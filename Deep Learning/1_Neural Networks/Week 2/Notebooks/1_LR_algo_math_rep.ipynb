{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Representation for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image is represented as an array of pixels Eg: 64p * 64 p. \n",
    "Each pixel has ameasure of R, G,B colour intensities.  \n",
    "So, a picture can be represented as a set of three 64 * 64 matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Math\n",
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image as a vector  of pixel intensities\n",
    "  - Each image can be represented as a vector, i.e the three matrices can be unpacked. \n",
    "into a single vector, of dimension ($n_x * 1$). A single image can then be represented as (x,y) where $x \\in R^{n_x}$ i.e x is a column vector and $y \\in (0,1)$\n",
    "2. The data set comprising of m training examples, can then be represented as -   \n",
    "$${(x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}), ..... , (x^{(m)},y^{(m)})}$$   \n",
    "3. All the $x^i$'s can be represented as a 2 D matrix, called X. m images, each a column vector of dim ($n_x,1$), can be represented as a matrix X of ($n_x$, m) dimension\n",
    "4. All the $y^i$'s  can be represented by a vector of (1,m) dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, an image is represented by a 3p * 3p resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47 30 22]\n",
      " [41 81  8]\n",
      " [20 73 98]]\n",
      "[[88 76 96]\n",
      " [46 30 99]\n",
      " [46 42 11]]\n",
      "[[91 19 31]\n",
      " [57 62 54]\n",
      " [16 37 45]]\n"
     ]
    }
   ],
   "source": [
    "r = np.random.randint(1,100,9).reshape(3,3)\n",
    "b = np.random.randint(1,100,9).reshape(3,3)\n",
    "g = np.random.randint(1,100,9).reshape(3,3)\n",
    "print(r)\n",
    "print(b)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single image can then be represented by a single vector, with rows unpacked into a column matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 30, 22, 41, 81,  8, 20, 73, 98, 88, 76, 96, 46, 30, 99, 46, 42,\n",
       "       11, 91, 19, 31, 57, 62, 54, 16, 37, 45])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr = np.append(np.append(r.reshape(9,1), b.reshape(9,1)), g.reshape(9,1))\n",
    "new_arr\n",
    "# n_x is therefore 27 in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For task of classification, given a feature vector (or a record in a tabular data), we want a probability of outcome.  \n",
    "What we want is an estimate of y i.e.    \n",
    "$$\\hat y = P(Y = 1 \\mid x)$$  \n",
    "such that   \n",
    "$$0 \\leq \\hat y \\leq 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Formulation ( not Hypothesis as we will not test hypothesis later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to estimate a matrix of weights (W) and an intercept (b) such that our hypothesis of the model form is: \n",
    "$$P(Y = 1 \\mid x) = g(w^T x + b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the function that ensures, we get a values between 0 to 1 no matter what the value of RHS is logistic or sigmoid function. \n",
    "$$ g(z) = \\log (\\frac{1}{1+e^{-z}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we estimate parameters w and b, for a new observation $x^{(i)}$, we can get the prediction as. \n",
    "$$ \\widehat {y^{(i)}}= g(w^T x^{(i)} + b)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation / Learning\n",
    "### 1. Loss Function         $L(y^{(i)}, \\widehat{y^{(i)}})$\n",
    "### 2. Cost Function      $ \\frac{1}{m}\\Sigma_{i=1}^{m}L(y^{(i)}, \\widehat{y^{(i)}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function should be - **  \n",
    "**1. Able to penalize deviations from actual values which are 1,0 in classification, i.e errors become large as predictions deviate from actuals, and hence we can try to minimize it in finding paramters of hypothesized model**  \n",
    "**2. Be convex function if possible, so that the approximate numerical techniques of finding optimum values (gradient descent) can converge reliably. Note that an exact solution is computationally expensive to find (more on this in Linear Algebra section)**  \n",
    "**3. More than one loss function forms can fulfil these criteria.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One that came to mind is below, but notice that \n",
    "- if y(i) is 1, then as the prediction moves away from 1, the error will become smaller. \n",
    "- if y(i) is 0, then as the prediction moves away from 0, the error will become smaller.   \n",
    "We will need to maximize this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ - [y^{(i)} \\log (1-\\widehat {y^{(i)}})+ (1- y^{(i)}) \\log (\\widehat {y^{(i)}})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better loss function which can be minimized because as the deviations increases, the error increases is -  \n",
    "$$ L(y^{(i)}, \\widehat{y^{(i)}}) =  - [ y^{(i)} \\log (\\widehat {y^{(i)}}) + (1-y^{(i)}) \\log (1-\\widehat {y^{(i)}})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function  \n",
    "$$J(w,b) = \\frac{1}{m}\\Sigma_{i=1}^{m}L(y^{(i)}, \\widehat{y^{(i)}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(w,b) = -\\frac{1}{m} \\Sigma_{i=1}^{m} [ y^{(i)} \\log (\\widehat {y^{(i)}}) + (1-y^{(i)}) \\log (1-\\widehat {y^{(i)}})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Basis for LR's Loss function / Maximum Likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We state the probability function as follows for Binary LR\n",
    "\\begin{align}\n",
    "P(Y = 1 \\mid x)  &= g(w^T x + b) = \\hat y \\\\\n",
    "P(Y = 0 \\mid x) & = 1 - \\hat y \n",
    "\\end{align}  \n",
    "A general form of stating LR's hypothesis is:  \n",
    "\\begin{align}\n",
    "P(Y\\mid x) = (\\widehat y)^y * (1-\\widehat y)^{1-y} \\\\\n",
    "\\end{align} \n",
    "Over a set of m data points, we would like to maximize the likelihood of predicted prob. being close to actual, which is:  \n",
    "\\begin{align}\n",
    "\\prod_{y=i}^m P(y^{(i)}\\mid x^{(i)}) = \\prod_{y=i}^m [(\\widehat {y^{(i)}})^{y^{(i)}} * (1-\\widehat {y^{(i)}})^{1-y^{(i)}}] \\\\\n",
    "\\end{align} \n",
    "\n",
    "Taking Log gives a function called Log Likelihood function, log makes this a monotonically increasing function, we want to maximize the function below, it is callaed ** Maximizing log likelohood ** :  \n",
    "\\begin{align}\n",
    "Max \\; [\\log \\prod_{y=i}^m P(y^{(i)}\\mid x^{(i)})] = Max \\; [\\Sigma_{i=1}^{m} [ y^{(i)} \\log (\\widehat {y^{(i)}}) + (1-y^{(i)}) \\log (1-\\widehat {y^{(i)}})]]\n",
    "\\end{align} \n",
    "\n",
    "Maximizing log likelihood is akin to minimizing loss, which is negative of Log Likelihood. We want to turn this into\n",
    "a minimization problem, also that the loss function will always be positive and its minima will be 0. We can see total cost as a monotonically decreasing function, which is solvable using gradient descent\n",
    "\n",
    "\\begin{align}\n",
    "Min \\; [-1 * \\log \\prod_{y=i}^m P(y^{(i)}\\mid x^{(i)})] = Min \\; [-1 * \\Sigma_{i=1}^{m} [ y^{(i)} \\log (\\widehat {y^{(i)}}) + (1-y^{(i)}) \\log (1-\\widehat {y^{(i)}})]]\n",
    "\\end{align} \n",
    "\n",
    "Finally we take average over m, to scale the coefficients better\n",
    "\\begin{align}\n",
    "Min \\; [\\frac{-1}{m} * \\log \\prod_{y=i}^m P(y^{(i)}\\mid x^{(i)})] & = Min \\; [\\frac{-1}{m} * \\Sigma_{i=1}^{m} [ y^{(i)} \\log (\\widehat {y^{(i)}}) + (1-y^{(i)}) \\log (1-\\widehat {y^{(i)}})]] \\\\\n",
    "\\end{align}  \n",
    "where Cost function is defined as : \n",
    "\\begin{align}\n",
    "J(w,b) & = -\\frac{1}{m} \\Sigma_{i=1}^{m} [ y^{(i)} \\log (\\widehat {y^{(i)}}) + (1-y^{(i)}) \\log (1-\\widehat {y^{(i)}})\n",
    "\\end{align} \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD -  draw a contour plot to show functional form of above cost function, assuming a single feature case (after learning matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rule based learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One idea could be to make a set of values of weights to iterate over and track changes to cost function.  \n",
    "The problem becomes dimensionally complex, even with 25 weights (for features), if you take 100 values for each   \n",
    "weight to take, there are $100^{25}$ combinations to try. This approach still will not get you a highly accurate solution, as it depends on how the choice of 100 values were arrived at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Learning using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritm used to solve optimization problems of the type  \n",
    "$$Min_{w1,w2,...wn} \\; J(w_1,w_2.., w_n)$$ where J is a convex function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps of the algo are -**. \n",
    "1. Initialize weights and intercept. If the cost function is strictly convex any random initialization will work, else initialization will affect the time to and value of convergence. Compute cost function.   \n",
    "2. Update weights and intercept simuateneously as $$w := w - \\alpha * \\frac{\\partial}{\\partial w} J(w,b)$$  \n",
    "and $$b := b - \\alpha * \\frac{\\partial}{\\partial b} J(w,b)$$\n",
    "  -  **Effect of learning rate: **Alpha is the learning rate. Gradient can be a quantity in range $(0,\\infty)$, so learning rate controls the size      of the step in changing weights. In a convex cost function scenario, one can think that a very small alpha can make the learning slow (close to global minima as gradient itself is close to 0) but will ensure convergence, large alpha can make you miss global minima, and move/oscillate around global minima as step size is bigger than distance to minima.\n",
    "3. Compute cost function, and check if it decreased. If not stop,else go to step 2.  \n",
    "**Inner Loop** : Iterate steps 2 and 3 until convergence, or upto a fixed no. of iterations  \n",
    "**Outer Loop**: The inner loop can itself be run multiple times to try different starting points, esp. when cost function. \n",
    "is not strictly convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why gradient descent converges to minima irrespective of starting values of weights?\n",
    "# TBD - explain using a cost function, over a data set, and a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Computation Graphs  \n",
    "A comutation can be broken down into a sequence of directed steps.  Node to represent a computation, edges/arrows to represent connection from input to node, or from node(input to next node) to another node. \n",
    "### Forward Pass.  \n",
    "* The computation of cost function can be depicted by such computation graph!  A forward pass from the graph leads to computed cost function. \n",
    "### Backward Pass  \n",
    "* The derivative of cost function with respect to an input variables or intermediate variable needs a back propagation on this computation graph. Link property of derivatives, can be viewed as Backpropagating on the computation graph.\n",
    "Let's say computation sequence of J, x,y is as x -> y - >J, then.  \n",
    "$$\\frac{\\partial}{\\partial x}J = \\frac{\\partial}{\\partial x}y * \\frac{\\partial}{\\partial y}J$$  \n",
    "So. first you compute $\\frac{\\partial}{\\partial y}J$ and then $\\frac{\\partial}{\\partial x}y$ to get to $\\frac{\\partial}{\\partial x}J$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass in gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In gradient descent, the updation of weights depends on computing partial derivative of Cost function w.r.t   \n",
    "weights and bias, hence a back propagation step is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradient descent - Forward and Backward propagation using computation graph on single training example / just Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function for logistic regression is defined as - \n",
    "Let estimated output be-   \n",
    "\\begin{align}\n",
    "z & = w^T * x^{(i)} + b\\\\\n",
    "a^{(i)} & = \\widehat {y^{(i)}} = g(z)\n",
    "\\end{align}  and loss function is  $$L(a^{(i)},y^{(i)}) =  - [ y^{(i)} \\log ({a^{(i)}}) + (1-y^{(i)}) \\log (1-{a^{(i)}})] \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;   (1)$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent will operate on the single example Loss function as - \n",
    "$$w = w - \\frac{\\partial}{\\partial w}L(a^{(i)},y^{(i)})   \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (2)$$  \n",
    "$$b = b - \\frac{\\partial}{\\partial b}L(a^{(i)},y^{(i)}) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking two inputs , the computation graph for Loss function can be represented as :  \n",
    "\n",
    "$x_1^{(i)}, x_2^{(i)}, w_1, w_2, b$  -----> $z^{(i)} = w_1*x_1^{(i)} + w_2*x_2^{(i)} + b$  -----> $a^{(i)} = g(z^{(i)})$ -----> $L(a^{(i)},y^{(i)}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing loss function starting from the inputs is forward propagation on this computation graph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing subscript (i) for single example:   \n",
    "\n",
    "$x_1, x_2, w_1, w_2, b$  -----> $z = w_1*x_1 + w_2*x_2 + b$  -----> $a = g(z)$ -----> $L(a,y) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute:  \n",
    "$$w_1 = w_1 - \\frac{\\partial}{\\partial w_1}L(a,y)$$  \n",
    "$$w_2 = w_2 - \\frac{\\partial}{\\partial w_2}L(a,y)$$  \n",
    "$$b = b - \\frac{\\partial}{\\partial b}L(a,y)$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing the partial derivatives requires back propagation, the derivative can be broken using chains rule as follows**. \n",
    "$$ \\frac{\\partial}{\\partial w_1} L(a,y) = \\frac{\\partial}{\\partial a} L(a,y) * \\frac{\\partial}{\\partial z} a * \\frac{\\partial}{\\partial w_1} z$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chain rule is then implemented as a back propagation in steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step1: Derivative of Loss function w.r.t a, symbilized da*   \n",
    "    \\begin{align}\n",
    "    \\frac{\\partial}{\\partial a}L(a,y) & = -1 * \\frac{\\partial}{\\partial a} (y\\log a + (1-y)(1-\\log a) = -1 * \\frac{y-a}{a(1-a)}\\\\   da & = \\frac{a-y}{a(1-a)}\n",
    "    \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step2: Derivative of Loss function w.r.t z, symbilized dz*  \n",
    "    \\begin{align}\n",
    "    \\frac{\\partial}{\\partial z}a & = \\frac{\\partial}{\\partial z} \\left(\\frac{1}{1+e^{-z}} \\right) = a(1-a)\\\\\n",
    "    dz & = da * \\frac{\\partial}{\\partial z}a = a-y \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (4)\n",
    "    \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step3: Derivative of Loss function w.r.t w_1, symbilized dw1*  \n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial w_1}z & = x_1 \\\\\n",
    "dw_1 & = \\frac{\\partial}{\\partial w_1}z * dz. \n",
    "\\end{align}  \n",
    "that is  \n",
    "$$ dw_1 = x_1*dz = x_1(a-y) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(5)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we get:\n",
    "\\begin{align}\n",
    " dw_1 & = x_1(a-y)\\\\\n",
    " dw_2 & = x_2(a-y)\\\\\n",
    " db & = (a-y)\n",
    " \\end{align}\n",
    " \n",
    " and consequently, weight updates are as:  \n",
    " \\begin{align}\n",
    " w_1 & := w_1 - \\alpha * dw_1 \\\\\n",
    " w_2 & := w_2 - \\alpha * dw_2 \\\\\n",
    " b & := b - \\alpha * db\n",
    " \\end{align}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gradient descent - Mathematical formulation for full training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get to the mathematical forumation of updating weights, the above solution for one training example and 2 features can be generalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Model Hypothesis:  \n",
    "\\begin{align}\n",
    "z^{(i)} = \\Sigma_{j=1}^n w_j * x_{j}^{(i)} + b \n",
    "\\end{align}\n",
    "Prediction for a single record \n",
    "\\begin{align}\n",
    "a^{(i)} = g(z^{(i)}) = \\frac{1}{1+e^{-z^(i)}}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "b. Cost Function to minimize and find values of weights and intercept:  \n",
    "\\begin{align}\n",
    " J(w_1,w_2,...,w_n,b) & = -\\frac{1}{m} \\Sigma_{i=1}^{m} [ y^{(i)} \\log ({a^{(i)}}) + (1-y^{(i)}) \\log (1-{a^{(i)}})\\\\\n",
    " J(w_1,w_2,...,w_n,b) & = \\frac{1}{m}\\Sigma_{i=1}^{m}L(a^{(i)},y^{(i)})\\\\\n",
    "\\end{align} \n",
    "\n",
    "c. Using gradient descent, we know the weights are updated as follows: \n",
    "\\begin{align}\n",
    "w_j & := w_j - \\alpha * \\frac{1}{m}\\frac{\\partial}{\\partial w_j} \\Sigma_{i=1}^{m} L(a^{(i)},y^{(i)})\\\\\n",
    "w_j & := w_j - \\alpha * \\frac{1}{m} \\Sigma_{i=1}^{m} \\frac{\\partial}{\\partial w_j} L(a^{(i)},y^{(i)})\\\\\n",
    "w_j & := w_j - \\alpha * \\frac{1}{m} \\Sigma_{i=1}^{m} dw_j\n",
    "\\end{align}\n",
    "d. Using results (4) and (5) derived for Loss function: \n",
    "\\begin{align}\n",
    "w_j & := w_j - \\alpha * \\frac{1}{m} \\Sigma_{i=1}^{m} x_j^{(i)}(a^{(i)}-y^{(i)})\\\\\n",
    "b & := b - \\alpha * \\frac{1}{m} \\Sigma_{i=1}^{m} (a^{(i)}-y^{(i)})\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8. Pseudo Code for implementing parameter learning using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize weights $w_1, w_2,... ,w_j, J, dw_j, db$ to 0  \n",
    "**Run steps 2,3,4 once, and then for x no. of times or until J continues increasing y no. of times**\n",
    "2. For i = 1 to m\n",
    "  - Compute $z^{(i)}, \\; a^{(i)}$\n",
    "  - Compute J=+ $L(a^{(i)},y^{(i)})$\n",
    "  - For j = 1 to n\n",
    "      - Compute $dw_j += x_j^{(i)}(a^{(i)}-y^{(i)})$\n",
    "3. Compute J as $J/m$  \n",
    "4. Update $b = b - \\frac{\\alpha}{m}* db$ , \n",
    "   For j = 1 to n update\n",
    "   - $w_j = w_j - \\frac{\\alpha}{m}* dw_j$  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
