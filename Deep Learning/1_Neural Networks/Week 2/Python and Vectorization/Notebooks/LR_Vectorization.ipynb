{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vectorization**: \n",
    "Method of utilizing functions that do faster numerical computation using parallel processing capabilities of CPU or GPU than for loops. \n",
    "In python numpy methods are vectorized, always perform better than for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized time = 0.7810592651367188 milli secs\n",
      "250355.004922\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "z = np.dot(a,b)\n",
    "end = time.time()\n",
    "print(\"Vectorized time = {0}{1}\".format(1000*(end -start),' milli secs'))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Loop time = 346.8492031097412 milli secs\n",
      "250355.004922\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "z = 0\n",
    "for i in range(1000000):\n",
    "    z+= a[i]*b[i]\n",
    "end = time.time()\n",
    "print(\"For Loop time = {0}{1}\".format(1000*(end -start),' milli secs'))\n",
    "print(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[[ 0  2  4  6]\n",
      " [ 4  6  8 10]\n",
      " [ 8 10 12 14]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize \n",
    "a = np.arange(12).reshape(3,4)\n",
    "b = np.arange(4).reshape(4,1)\n",
    "c = np.zeros_like(a)\n",
    "\n",
    "# a.shape = (3,4)\n",
    "# b.shape = (4,1)\n",
    "\n",
    "for i in range(3):\n",
    "  for j in range(4):\n",
    "    c[i][j] = a[i][j] + b[j]\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  4,  6],\n",
       "       [ 4,  6,  8, 10],\n",
       "       [ 8, 10, 12, 14]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep Learning, we will mostly deal with massive calculations, vectorization can make a big difference in completing\n",
    "a single iteration. \n",
    "On smaller data sets, it used to be 'good to have' option, in deep learning, it becomes must have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy methods perform vectorization and are way faster than loops. \n",
    "Example: element wise operations performed by functions-\n",
    "exp(x), abs(x), exp(x) , log(x), 1/x where x is a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of Logistic Regression using representation in 1_LR_algo_math_rep.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of algorithm implementation\n",
    "\n",
    "|-- process_data : Function to convert an array of images of size $m * num_{px} * num_{px} * 3$ into a two dimensional matrix  \n",
    "|-- 'Initialize Weights' : Function to Initialize weights   \n",
    "|-- 'Sigmoid' : Activation Function for LR, can be changed so keep as a separate function  \n",
    "|-- 'propagate' : Function to do forward propagation to compute activation function, Cost function, backward          \n",
    "                   propgation to compute change in weights  \n",
    "|-- 'optimize' : Function to run iterations   \n",
    "|-- 'predict'. : Function to convert predicted probability to label  \n",
    "|-- 'lr_model' : Function utilizing above functions to take a dataset, no. of iterations, alpha and return wights,                      bias, Loss values after trainining.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imageine Loading the data (cat/non-cat) after loading libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline\n",
    "#train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11]]],\n",
       "\n",
       "\n",
       "       [[[12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[16, 17],\n",
       "         [18, 19]],\n",
       "\n",
       "        [[20, 21],\n",
       "         [22, 23]]],\n",
       "\n",
       "\n",
       "       [[[24, 25],\n",
       "         [26, 27]],\n",
       "\n",
       "        [[28, 29],\n",
       "         [30, 31]],\n",
       "\n",
       "        [[32, 33],\n",
       "         [34, 35]]],\n",
       "\n",
       "\n",
       "       [[[36, 37],\n",
       "         [38, 39]],\n",
       "\n",
       "        [[40, 41],\n",
       "         [42, 43]],\n",
       "\n",
       "        [[44, 45],\n",
       "         [46, 47]]],\n",
       "\n",
       "\n",
       "       [[[48, 49],\n",
       "         [50, 51]],\n",
       "\n",
       "        [[52, 53],\n",
       "         [54, 55]],\n",
       "\n",
       "        [[56, 57],\n",
       "         [58, 59]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.arange(60).reshape((5,3,2,2))\n",
    "# Interpret the array as 5 images each represnted by 3 2*2 arrays\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17 18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      " [36 37 38 39 40 41 42 43 44 45 46 47]\n",
      " [48 49 50 51 52 53 54 55 56 57 58 59]]\n"
     ]
    }
   ],
   "source": [
    "# To turn this into a 2D array, each image represented by a column\n",
    "a2 = a1.reshape(5,-1) # the unrolling happens row by row and in sequence for each of 3 arrays corresponding to an image\n",
    "print(a2)\n",
    "a3 = a2.T.copy() # copy because T produces a view, and changes made to view are broadcasted back\n",
    "#then take transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train_x):\n",
    "    '''\n",
    "    Function flattern the array to two dimen\n",
    "    Arguments:\n",
    "    train_x : numpy array of size m * num_{px} * num_{px} * 3\n",
    "    \n",
    "    Returns:\n",
    "    train_x_flatten : A two dim. array of dim n*m, where n= num_{px} * num_{px} * 3; after reshaping and normalizing\n",
    "    '''\n",
    "    train_x_flatten = train_x.reshape(train_x.shape[0],-1).T.copy\n",
    "    train_x_flatten /= 255 # Normalize by dividing by maximum possible, normalizing enable gradient descent to train \n",
    "                           # faster\n",
    "        \n",
    "    return train_x_flatten\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[ 0.33813498]\n",
      " [ 0.60331013]]\n",
      "b = 0.4470709640209256\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights(dim):\n",
    "    '''\n",
    "    Argumnts : \n",
    "    dim : scalar\n",
    "    \n",
    "    Returns:\n",
    "    w : n*1 matrix\n",
    "    b : scalar\n",
    "    '''\n",
    "    w_init = np.random.rand(dim,1)\n",
    "    b_init = np.random.rand()\n",
    "    assert(w_init.shape == (dim,1))\n",
    "    assert(isinstance(b_init, float) or isinstance(b_init, int) )\n",
    "    dic = {\"w\" : w_init,\n",
    "          \"b\" : b_init}\n",
    "    return dic\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ 1 line of code)\n",
    "    w_init = np.zeros((dim,1))\n",
    "    b_init = 0\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w_init.shape == (dim, 1))\n",
    "    assert(isinstance(b_init, float) or isinstance(b_init, int))\n",
    "    \n",
    "    dic = {\"w\" : w_init,\n",
    "          \"b\" : b_init}\n",
    "    return dic\n",
    "\n",
    "# Unit Test\n",
    "dim = 2\n",
    "dic = initialize_weights(dim)\n",
    "print (\"w = \" + str(dic['w']))\n",
    "print (\"b = \" + str(dic['b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sigmoid Function to compute $ a^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [ 0.5         0.88079708]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    Argumnts : \n",
    "    z : 1* m matrix\n",
    "    \n",
    "    Returns:\n",
    "    A : 1*m matrix'''\n",
    "    #print(\"dimension of X is {0}, W is {1}, B is {2}\".format(str(X.shape), str(W.shape),str(B.shape)))\n",
    "    A = 1/(1 + np.exp(-1*z))\n",
    "    return(A)\n",
    "\n",
    "# Unit test\n",
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))\n",
    "# Expected O/P :  [ 0.5         0.88079708]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Propagage - forward and back in one iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.squeeze reduces dimensions of an array by removing dimension present as 1\n",
    "a = np.arange(20).reshape(1,4,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[ 0.99845601]\n",
      " [ 2.39507239]]\n",
      "db = [ 0.00145558]\n",
      "cost = 5.801545319394553\n"
     ]
    }
   ],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    '''\n",
    "    Arguments:\n",
    "    Y: 1*m vector\n",
    "    X: n*m matrix\n",
    "    w: n*1 column vector\n",
    "    b: scalar\n",
    "    Returns:\n",
    "    Cost : Negative likelihood \n",
    "    dw : Matrix of Change in weights, of n*1 dims\n",
    "    db : Change in bias, a scalar'''\n",
    "    \n",
    "  \n",
    "    m = X.shape[1]\n",
    "    # Forward propagation\n",
    "    z = np.dot(w.T,X)+ b  # use of broadcasting\n",
    "    a = sigmoid(z)\n",
    "    loss = -1 *(Y * np.log(a) + (1-Y)*(np.log(1-a)))\n",
    "    cost = np.sum(loss, axis = 1)/m\n",
    "    cost = cost.squeeze()\n",
    "    assert(cost.shape==())\n",
    "    dz = a - Y\n",
    "    dw = np.dot(X, dz.T) / m# n*1 vec\n",
    "    assert(dw.shape == w.shape)\n",
    "    db = np.sum(dz, axis = 1)/m\n",
    "    assert(db.dtype == float)\n",
    "    grads = {'dw' : dw,\n",
    "           'db' : db}\n",
    "    return grads, cost\n",
    "\n",
    "## Unit test\n",
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "dw = [[ 0.99845601]\n",
    " [ 2.39507239]]\n",
    "db = [ 0.00145558]\n",
    "cost = 5.801545319394553"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[-0.08608643]\n",
      " [ 0.10971233]]\n",
      "b = [-0.14427427]\n",
      "dw = [[ 0.12311093]\n",
      " [ 0.13629247]]\n",
      "db = [-0.14923916]\n"
     ]
    }
   ],
   "source": [
    "def optimize(w, b, X, Y, iters, alpha, print_cost = False):\n",
    "    '''\n",
    "    Arguments:\n",
    "       X     : n*m matrix of numerical features\n",
    "       y     : 1*m vector of binary labels\n",
    "       iters  : max. no of iterations if exit criteria is not satisfied, to avoid long training iteration,\n",
    "              switch to using larger learning rate\n",
    "       alpha : learning rate  \n",
    "       print_cost = If cost is to be printed every 100 iterations\n",
    "       \n",
    "    Returns:\n",
    "    params : dictionary containing the weights w and bias b\n",
    "    grads : dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs : list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    '''\n",
    "    #2. Compute z\n",
    "    #3. Compute a\n",
    "    #4. Compute Cost\n",
    "    #5. Adjust weights and bias\n",
    "    #6. Compute cost\n",
    "    #7. Check if cost of step 5 decreases than in step 3, if yes go to step 2, if no decrease happened for 10 iterations\n",
    "    #  stop, and return cost, weights, bias\n",
    "    params ={}\n",
    "    grads ={}\n",
    "    costs =[]\n",
    "    for i in range(iters):\n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        costs.append(cost)\n",
    "        w = w - alpha * grads['dw']\n",
    "        b = b - alpha * grads['db']\n",
    "        # Print the cost every 1000 training iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    params = {'w' : w, 'b' : b}\n",
    "    return params, grads, costs    \n",
    "    \n",
    "## Unit test\n",
    "params, grads, costs = optimize(w, b, X, Y, iters= 100, alpha = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output**\n",
    "w = [[ 0.19033591]\n",
    " [ 0.12259159]]\n",
    "b = [ 1.92535983]\n",
    "dw = [[ 0.67752042]\n",
    " [ 1.41625495]]\n",
    "db = [ 0.2191945]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = {'probs': array([[ 0.52241976,  0.50960677,  0.34597965]]), 'labels': array([[ 1.,  1.,  0.]])}\n"
     ]
    }
   ],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    dic -- dic of numpy arrays (vectors) containing probabilities and all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    z = np.dot(w.T,X) + b\n",
    "    predicted_probs_y = sigmoid(z)\n",
    "    predicted_labels_y = np.zeros((1,m))\n",
    "    predicted_labels_y = np.where(predicted_probs_y > 0.5,1,predicted_labels_y)\n",
    "    assert(predicted_probs_y.shape == (1,m))\n",
    "    assert(predicted_labels_y.shape == (1,m))\n",
    "    dic = {'probs' : predicted_probs_y,\n",
    "          'labels' : predicted_labels_y}\n",
    "    return dic\n",
    "\n",
    "# Unit Test\n",
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(X_train,Y_train, X_test, Y_test, alpha = 0.05, iters = 2000, print_cost = True):\n",
    "    '''\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train : training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    iters -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    alpha -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    '''\n",
    "    assert(X_train.shape[1]==Y_train.shape[1])\n",
    "    assert(Y_train.shape[0] == 1)\n",
    "    #dic = initialize_weights(X_train.shape[0])\n",
    "    dic = initialize_with_zeros(X_train.shape[0])\n",
    "    w = dic['w']\n",
    "    b = dic['b']\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, iters, alpha, print_cost)\n",
    "    # Print training error\n",
    "    preds_dic_train = predict(w, b, X_train)\n",
    "    preds_dic_test = predict(w, b, X_test)\n",
    "    accuracy_train = np.sum(preds_dic_train['labels'] == Y_train)/Y_train.shape[1]\n",
    "    accuracy_test = np.sum(preds_dic_test['labels'] == Y_test)/Y_test.shape[1]\n",
    "    print(\"The training accuracy is {0} %\".format(accuracy_train*100))\n",
    "    print(\"The testing accuracy is {0} %\".format(accuracy_test*100))\n",
    "    \n",
    "    d = {'w' :w,\n",
    "         'b' :b,\n",
    "         'costs': costs,\n",
    "          'learning_rate' : alpha,\n",
    "          'iterations' : iters}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a structured data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'target', 'target_names'] (569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "print(dir(data), data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,) (569,)\n"
     ]
    }
   ],
   "source": [
    "no_train = int(0.7*569)\n",
    "np.random.seed(1001)\n",
    "train_sample = np.random.choice(a = np.arange(569), size = no_train,replace = False)\n",
    "assert(len(np.unique(train_sample))==no_train)\n",
    "\n",
    "train_index = np.isin(np.arange(569),train_sample)\n",
    "test_index = ~train_index\n",
    "print(train_index.shape, test_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 398) (30, 171) (1, 398) (1, 171)\n"
     ]
    }
   ],
   "source": [
    "train_X = data.data[train_index].T.copy() # boolean indexing creates a copy; T creates a view\n",
    "train_Y = data.target[train_index].reshape(1,-1)\n",
    "test_X = dt[test_index].T.copy()\n",
    "test_Y = data.target[test_index].reshape(1,-1)\n",
    "print(train_X.shape, test_X.shape,train_Y.shape,test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X matrices\n",
    "train_X = (train_X - np.mean(train_X, axis = 1).reshape(-1,1))/np.std(train_X,axis = 1).reshape(-1,1)\n",
    "test_X = (test_X - np.mean(test_X, axis = 1).reshape(-1,1))/np.std(test_X,axis = 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 1000: 0.053462\n",
      "Cost after iteration 2000: 0.045436\n",
      "Cost after iteration 3000: 0.041301\n",
      "Cost after iteration 4000: 0.038535\n",
      "Cost after iteration 5000: 0.036470\n",
      "Cost after iteration 6000: 0.034835\n",
      "Cost after iteration 7000: 0.033488\n",
      "Cost after iteration 8000: 0.032349\n",
      "Cost after iteration 9000: 0.031364\n",
      "The training accuracy is 38.19095477386934 %\n",
      "The testing accuracy is 35.08771929824561 %\n"
     ]
    }
   ],
   "source": [
    "model = lr_model(train_X, train_Y, test_X, test_Y, alpha = 0.1, iters = 10000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18172053c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(model['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per thousands)')\n",
    "plt.title(\"Learning rate =\" + str(model[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is: 0.01\n",
      "The training accuracy is 38.19095477386934 %\n",
      "The testing accuracy is 35.08771929824561 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "learning rate is: 0.001\n",
      "The training accuracy is 38.19095477386934 %\n",
      "The testing accuracy is 35.08771929824561 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "learning rate is: 0.0001\n",
      "The training accuracy is 38.19095477386934 %\n",
      "The testing accuracy is 35.08771929824561 %\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a179c26a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = lr_model(train_X, train_Y, test_X, test_Y, iters = 10000, alpha = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (thousands)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: \n",
    "- Different learning rates give different costs and thus different predictions results.\n",
    "- If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost). \n",
    "- A lower cost doesn't mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.\n",
    "- In deep learning, usually recommend that : \n",
    "    - Choose the learning rate that better minimizes the cost function.\n",
    "    - If your model overfits, use other techniques to reduce overfitting. (TBD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD : Run the algorithm on a images data later, confirm cost function can oscillate up an downs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code snipped below from scipy to process image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"my_image.jpg\"   # change this to the name of your image file \n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
