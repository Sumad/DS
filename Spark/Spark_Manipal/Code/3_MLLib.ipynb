{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics\n",
    "1. ML and MLLib libraries \n",
    "  - Data frame vs RDD based , latter getting deprecated\n",
    "2. Matrix support \n",
    "  - Sparse and Dense vectors and matrices \n",
    "3. Working with libSVM kind of data. \n",
    "4. Feature Transformers  \n",
    "5. Feature Extractors   \n",
    "6. Feature Selectors \n",
    "7. Model selection and Tuning \n",
    "8. Pipelines\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Linear Algebra Module \n",
    "- Dense vectors, matrices   \n",
    "  - Dense and Sparse are interconvertible, Dense rep. is essentially same as numpy array \n",
    "- Sparse vectors, matrices \n",
    "  - Can take in scipy.sparse type matrices ( check how to create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "\n",
    "from pyspark.ml.linalg import SparseMatrix, DenseMatrix, Vectors\n",
    "\n",
    "x = Vectors.dense(np.arange(1,20,1))\n",
    "x\n",
    "print(type(x))\n",
    "\n",
    "x.dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import SparseVector\n",
    "a = SparseVector(4, [1, 3], [3.0, 4.0])\n",
    "a\n",
    "\n",
    "# conversion of dense matri to sparse or numpy array\n",
    "x = DenseMatrix(5,6, range(30))\n",
    "x\n",
    "\n",
    "x.toSparse()\n",
    "\n",
    "x.toArray()\n",
    "\n",
    "# sparse matrix types in scipy - two of ones that allow inverse calculation\n",
    "from scipy.sparse import csc_matrix, csr_matrix \n",
    "\n",
    "A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
    "A\n",
    "\n",
    "print(A)\n",
    "\n",
    "B = csc_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
    "B\n",
    "\n",
    "print(B)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "denseVec = Vectors.dense(1.0, 2.0, 3.0)\n",
    "size = 3\n",
    "idx = [1, 2] # locations of non-zero elements in vector\n",
    "values = [2.0, 3.0]\n",
    "sparseVec = Vectors.sparse(size, idx, values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Working with libSVM kind of data.  \n",
    "- libsvm is a popular data format for large scale ML esp, used in popular SVM libraries LIBSVM and LIBLINEAR. \n",
    "- Format is - \n",
    "  - label index1:value1 index2:value2 ...  \n",
    "  - index is 1 based, post reading made to 0 based in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libsvm = spark.read.format('libsvm').load('/user/sumad/Data/sample_libsvm_data.txt')\n",
    "libsvm.show(5)\n",
    "+-----+--------------------+\n",
    "|label|            features|\n",
    "+-----+--------------------+\n",
    "|  0.0|(692,[127,128,129...|\n",
    "|  1.0|(692,[158,159,160...|\n",
    "|  1.0|(692,[124,125,126...|\n",
    "|  1.0|(692,[152,153,154...|\n",
    "|  1.0|(692,[151,152,153...|\n",
    "+-----+--------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Feature transformers \n",
    "- Ref : https://spark.apache.org/docs/2.3.0/ml-features.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Categorical feature encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.1 String Indexer  \n",
    "- Creates a numeric index on a categorical column, essentially assigning frequenct based index to each \n",
    "  category  \n",
    "- When fit on a new data set, three ways to handle new categories encountered : error, remove records, assign \n",
    "  a new index to all new cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ind = StringIndexer(inputCol= 'category', outputCol = 'catIndex',\n",
    "handleInvalid='error', stringOrderType='frequencyDesc')\n",
    "df_indexed = s_ind.fit(df).transform(df)\n",
    "df_indexed.show()\n",
    "\n",
    "+---+--------+--------+\n",
    "| id|category|catIndex|\n",
    "+---+--------+--------+\n",
    "|  0|       a|     0.0|\n",
    "|  1|       b|     2.0|\n",
    "|  2|       c|     1.0|\n",
    "|  3|       a|     0.0|\n",
    "|  4|       a|     0.0|\n",
    "|  5|       c|     1.0|\n",
    "+---+--------+--------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.2 One hot encoding \n",
    "- Unlike sklearn's one hot encoder, as default, it uses a feature vector of length n-1 to represent all categories of a column . dropLast = True ensure n-1 feature vec length\n",
    "- Treatment of new category is as in StringIndexer. \n",
    "- The ouput representation is a sparse vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "df = spark.createDataFrame([\n",
    "    (0.0, 1.0),\n",
    "    (1.0, 9.0),\n",
    "    (2.0, 1.0),\n",
    "    (3.0, 2.0),\n",
    "    (0.0, 1.0),\n",
    "    (2.0, 4.0)\n",
    "], [\"categoryIndex1\", \"categoryIndex2\"])\n",
    "\n",
    "oh_enc = OneHotEncoderEstimator(inputCols= [\"categoryIndex1\", \"categoryIndex2\"],\n",
    "                      outputCols= [\"oh_categoryIndex1\", \"oh_categoryIndex2\"],\n",
    "                      handleInvalid='error',dropLast=True)\n",
    "df_enc = oh_enc.fit(df).transform(df)\n",
    "\n",
    "+--------------+--------------+-----------------+-----------------+\n",
    "|categoryIndex1|categoryIndex2|oh_categoryIndex1|oh_categoryIndex2|\n",
    "+--------------+--------------+-----------------+-----------------+\n",
    "|           0.0|           1.0|    (3,[0],[1.0])|    (9,[1],[1.0])|\n",
    "|           1.0|           9.0|    (3,[1],[1.0])|        (9,[],[])|\n",
    "|           2.0|           1.0|    (3,[2],[1.0])|    (9,[1],[1.0])|\n",
    "|           3.0|           2.0|        (3,[],[])|    (9,[2],[1.0])|\n",
    "|           0.0|           1.0|    (3,[0],[1.0])|    (9,[1],[1.0])|\n",
    "|           2.0|           4.0|    (3,[2],[1.0])|    (9,[4],[1.0])|\n",
    "+--------------+--------------+-----------------+-----------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndextoString\n",
    "Response Encoding\n",
    "VectorIndexer (Improves performance, automates cat. identification)\n",
    "Inreraction ( gives a cartesian product, how is it used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.2 Continuous Feature Transformers \n",
    "- Scalers \n",
    "- Bucketizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
