---
title: "Problem _Definition_and Sol_Outline"
author: "Sumad Singh"
date: "November 12, 2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Read Data
library(data.table)
library(dplyr)
library(car)
library(rlang)

dir <- "C:/Users/sumad.singh/Documents/DS/Supervised Learning/SL201/Logistic Regression/Problem1"
data <- fread(input = file.path(dir, "Logistic Regression Data_Responder.csv"),na.strings = c("",NA),
      colClasses = c(rep("numeric",12),"integer"))

# Fix names in dataset

colnames(data) <- c("Internal_rating","Credit_rating","Age","salary",             
                    "Overall_spend","Survey_score","Last_quarter_spend","Past_purchases_band",
                    "Premium_score","Purchase_capacity","net_worth","Bank_balance",       
                    "Responder")
```

### Describe problem and  variables

Develop a model to predict the probability of responding. The model will be used to prioritize contact
with the customers
1. Model could be non-linear or linear
2. Response rate is 6%

```{r}
prop.table(table(x = data$Responder))
```

3.Summary of variables :All variables are numeric  

### Outline Solution approach
The below step will be taken to develop the best predictive model. Method drives a lot of  
steps, we will consider logistic, single tree, ensembles - RF and GBM

1. Divide into train (70%) and val (30%)  
2. Exploratory data analysis  
2.1 CHECK DATA QUALITY  
2.1.1 EXTENT OF MISSING VALUES IN COMPLETE DATA, HOW TO FIX?  - Fix needed for logistic, RF
2.1.2 NO. OF LEVELS FOR CAT. VARIABLES, DROP VARIABLE OR CONSOLIDATE LEVELS?  - Can GBM handle?
2.1.3 OUTLIERS IN NUMERICAL VARIABLES, CAPPING REQUIRED?  - handling needed for logistic
2.1.4 INFLUENTIAL CASES - DROP OR KEEP; DROP FOR LOGISTIC  

2.2 EXPLORE RELATIONSHIPS TO DECIDE ON APPROACH OF SUPERVISED METHOD  
2.2.1 UNIVARIATE DISTRIBUTIONS OF NUMERICAL VARS.- HIGH NUMBER OF HIGH SKEWS, MEANS RF COULD BE GOOD, LOGISTIC WILL NEED  SOME TRANSFROMATIONS TO MAKE THEIR DISTRIBUTIONS CLOSE TO NORMAL?
2.2.2 WEIGHT OF EVIDENCE WITH DECILES - SHOW IF RELATIONSHIP IS LINEAR, EXTENT OF NON-LINEARITY,   
      CAN IT BE CAPTURED BY A LINEAR MODEL WITH TRANSFORMATIONS  
2.2.3 CORRELATIONS B/W NUMERICAL VARIABLES , high number of high correlated vars.? - RF is not good 
2.2.4 CORRELATION B/W CATEGORICAL VARIABLES  
2.2.5 MULTICOLINEARITY : CHECK VIF FOR EACH VARIABLES BY FITTING A LINEAR MODEL  

3. DECIDE ASSESSMENT METRIC - LOGLOSS, AUC for overall ability of model to separate 1 from 0 class;  
  KS, Lift Chart to assess preditive performance in deciles, checks which model performs better in   
  which deciles  
  
4. FEATURE CREATION 
4.1 FEATURES TO USE IN LOGISTIC REGRESSION
4.2 FOR USE IN TREES AND ENSEMBLES

5. FEATURE/VARIABLE SELECTION METHODOLOGY ( FOR lOGISTIC, TREES, RF AND TREE ENSEMBLES DO VAR. SEL.)
5.1 



```{r}



```

```{r}
# Outline directory structure
```

