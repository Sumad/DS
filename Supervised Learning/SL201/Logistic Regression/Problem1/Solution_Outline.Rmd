---
title: "Problem _Definition_and Sol_Outline"
author: "Sumad Singh"
date: "November 12, 2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Read Data
library(data.table)
library(dplyr)
library(car)
library(rlang)

dir <- "/Users/sumad/Documents/DS/Supervised Learning/SL201/Logistic Regression/Problem1"
data <- fread(input = file.path(dir, "Logistic Regression Data_Responder.csv"),na.strings = c("",NA),
      colClasses = c(rep("numeric",12),"integer"))

# Fix names in dataset

colnames(data) <- c("Internal_rating","Credit_rating","Age","salary",             
                    "Overall_spend","Survey_score","Last_quarter_spend","Past_purchases_band",
                    "Premium_score","Purchase_capacity","net_worth","Bank_balance",       
                    "Responder")
```

### DDESCRIBE PROBLEM AND  VARIABLES

Develop a model to predict the probability of responding. The model will be used to prioritize contact
with the customers
1. Model could be non-linear or linear
2. Response rate is 6%

```{r}
prop.table(table(x = data$Responder))
```

3.Summary of variables :All variables are numeric  

### OUTLINE SOLUTION APPROACH
THE BELOW STEPS WILL BE TAKEN TO DEVELOP THE BEST PREDICTIVE MODEL. METHOD DRIVES A LOT OF STEPS, WE WILL CONSIDER  
LOGISTIC, SINGLE TREE, ENSEMBLE METHODS ON TREES - RF AND GBM, SVM AND ANN

1. DIVIDE INTO TRAIN (70%) AND VAL (30%), WE WILL USE VAL TO DO OUT OF SAMPLE VALIDATIONS. EXPLAINATION -  
*OUT OF SAMPLE VALIDATION*   
LIFT CHART, CUMULATIVE GAINS CHARTS, KS STATISTIC OF A SET OF CONTENDER MODELS TO COMPARE HOW WELL THEY CLASSIFY   
ACROSS DECILES.  
 
*IN SAMPLE MODEL SELECTION* FOR MODEL SELECTION (METHOD + VARIABLES + TUNING PARAMETERS)        
- THE EMPHASIS IS TO FIX THE METHOD AND CREATE VARIABLES, SELECT VARIABLES AND TUNE PARAMETERS FIRST USING CROSS VALIDATE  
- THIS CARES TO AVOID OVERFITTING BY CHOOSING INFORMATIVE VARIABLES   
- THE BEST MODLES WITHIN DIFFERENT METHODS AND TUNING PARAMETERS COULD THEN BE COMPARED ON A SINGLE MEASURE, DERIVED    
  FROM CROSS VALIDATION RESULTS, AS WELL AS ON OUT OF SAMPLE MEASURES  

2. EXPLORATORY DATA ANALYSIS
2.1 CHECK DATA QUALITY, EMIT A SUMMARY
2.1.1 EXTENT OF MISSING VALUES IN COMPLETE DATA, HOW TO FIX?    
2.1.2 NO. OF LEVELS FOR CAT. VARIABLES, DROP VARIABLE OR CONSOLIDATE LEVELS?  
2.1.3 OUTLIERS IN NUMERICAL VARIABLES, CAPPING REQUIRED?   
2.1.4 INFLUENTIAL CASES - DROP OR KEEP; DROP FOR LOGISTIC   

*Article on which techniques can handle cardinality, missing values, outliers and influential observations and which cannot* 

2.2 EXPLORE RELATIONSHIPS TO DECIDE ON VARIABLE CREATION AND METHODS TO BE USED, EMIT CHARTS AND SUMMARIES
2.2.1 UNIVARIATE DISTRIBUTIONS OF NUMERICAL VARS. 
*HIGH NUMBER OF HIGH SKEWS, MEANS RF COULD BE GOOD, LOGISTIC WILL NEED  SOME TRANSFROMATIONS TO MAKE THEIR DISTRIBUTIONS CLOSE TO NORMAL?*
2.2.2 WEIGHT OF EVIDENCE WITH DECILES - SHOW IF RELATIONSHIP IS LINEAR, EXTENT OF NON-LINEARITY,   
      CAN IT BE CAPTURED BY A LINEAR MODEL WITH TRANSFORMATIONS  
2.2.3 CORRELATIONS B/W NUMERICAL VARIABLES , high number of high correlated vars.? 
*RF is not good* 
2.2.4 CORRELATION B/W CATEGORICAL VARIABLES  
2.2.5 MULTICOLINEARITY : CHECK VIF FOR EACH VARIABLES BY FITTING A LINEAR MODEL  

3. DECIDE METHODS TO BE USED, ASSESSMENT METRIC FOR COMPARING MODELS USING CROSS VALIDATED MTERIC WITHIN SAMPLE/TRAIN.  
   SUMMARIZE IN NOTES.  
*LOGLOSS, AUC for overall ability of model to separate 1 from 0 class*  

4. DECIDE VALIDATION METRICS FOR OUT OF SAMPLE VALIDATION.SUMMARIZE IN NOTES.   
*KS, Lift Chart to assess preditive performance in deciles FOR CANDIDATE MODELS, IN ADDITION TO GETTING A BENCHMARK OF THE ASSESSMENT METRIC ON VALIDATION DATA FOR EACH CANDIDATE MODEL*  
  
5. FEATURE CREATION 
4.1 DOCUMENT FEATURES TO USE BASED ON METHOD. SUPPORT IS BASED ON STEP2 RESULTS.   
4.2 THIS STEP COULD BE AUTOMATED AT TIMES, TO PUT THE BURDEN OF SELECTION ON FEATURE SELECTION PROCESS. SHOULD BE DOCUMENTED.  

6. FEATURE/VARIABLE SELECTION METHODOLOGY ( FOR lOGISTIC, TREES, RF AND TREE ENSEMBLES DO VAR. SEL.)

### DESCRIBE DIRECTORY STRUCTURE FOR CODE, PLOTS, SUMMARIES TO BE ORGANIZED  

**SCRIPTS** WILL BE VERSION CONTROLLED, IF THEY ARE TRYING TO MAKE INCREMENTAL CHANGES

1. READ AND SPLIT : SUB-DIRECTORIES  
- FUNCTIONS: SUBDIRECTORY TO STORE ALL READ AND SPLIT FUNCTIONS  
- SCRIPTS : CODE TO READ, FIX COLUMN CLASSES,DOCUMENT SCALE, CHANGE NAMES ETC    
- DATA : STORE COLUMN CLASSES, FILES AFTER SPLIT    

2. EDA : SUB-DIRECTORIES     
- FUNCTIONS: SUBDIRECTORY TO STORE ALL EDA FUNCTIONS  
- SCRIPTS : CODE TO EMIT EDA OUTPUTS 

3. VARIABLE CREATION :     
- DIR. BY METHODS, AND VERSION OF SCRIPTS  TO CREATE VARIABLES ON TOP OF STEP 1 FILE  
- FUNCTIONS : CREATE FUNCTIONS TO APPLY A TRANSFORMATION ON A VARIABLE SET, LIKE CAPPING  

4. VARIABLE SELECTION : SUB-DIRECTORIES
- SCRIPTS  
- FUNCTIONS

5. MODELING : SUB-DIRECTORIES
5.1 BY METHOD  
5.1.1 SCRIPTS : TO DO FINAL STEPS ON DATA FOR MODEL FITTING, FIT MODELS, SAVE MODEL OBJECTS, TRAINING STATISTICS, CROSS VALIDATION  STATISTICS  FOR IN SAMPLE MODEL COMPARISON
5.1.2 RESULTS : PLOTS

5.2 FUNCTIONS: UTILITIES TO COMPARE MODELS 
5.3 FINAL_SELECTION AND VALIDATION  
5.3.1 FUNCTIONS  
5.3.2 RESULTS

