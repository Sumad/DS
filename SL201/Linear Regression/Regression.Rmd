---
title: "Linear Regression"
author: "Sumad Singh"
date: "9/22/2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# REGRESSION - PREDICTIVE TECHNIQUE FOR CONTINUOUS DEPENDENT VARIABLES, PARAMETRIC
# CLASSIFICATION - FOR DISCRETE OUTCOME, PARAMETRIC AND NON PARAMETRIC

SECTION A  
##1. REGRESSION AS A TECHNIQUE - THE EQUATION AND USES  
ESTABLISH A LINEAR RELATIONSHIP  
EXLAIN VARIATION USING OTHER VARIABLES    
VALIDATE HYPOTHESIS ABOUT RELATIONSHIPS  
REGRESSION TO MEAN  
ASSUMPTION OF ADDITIVE RELTIONSHIPS IN STATING LINEAR REGRESSION

##2. HYPOTHESIZED RELATIONSHIP, PRF AND SRF
HOW EDA PLAYS A ROLE IN FORMULATING THE HYPOTHESIS  
WHY USE AN INTERCEPT IN THE MODEL

##3. ASSUMPTIONS OF LINEAR MODEL

##4. ESTIMATION TECHNIQUES USING DATA- PROPERTIES OF GOOD ESTIMATION TECHNIQUES, WHY OLS IS GOOD
BLUE IF NO HETEROSCEDASTICITY AND AUTOCORRELATION
###4.1 DATA SELECTION, SAMPLING, OUTLIERS,INFLUENTIAL OBSERVATION CONSIDERATIONS
###4.2 TRANSFORMATION OF CATEGORICAL VARIABLES
####4.2.1 DUMMY VARIABLES AND DUMMY VARIABLE TRAP
####4.2.2 BASE LEVEL SELECTION
####4.2.3 IDENTIFICATION OF INTERACTIONS
This helps hypothesize, but whether it increase variance is tested by independent test set
#####4.2.3.1 GRAPHICAL METHOD  
#####4.2.3.2 USE OF DECISION TREES OR CHAID
#### 4.2.4 HOW OUTLIERS AND INFLUENTIAL OBSERVATIONS AFFECT ESTIMATION

##5. PARAMETER ESTIMATES, THEIR STD. ERROR, P VALUE - INTERPRETATION
###5.1 HOW CAN WE COMPARE PARTIAL REGRESSION COEFFICIENTS
###5.2 HOW SHOULD DIFFERENCE IN SCALE OF VARIABLES BE MANAGED?
RUN REGRESSION ON STANDARDIZED AND CONVERT TO ACTUAL SCALES?

##6.   VALIDATION OF ASSUMPTIONS - HOW TO,CONSEQUENCES OF FAILURE, TREATMENT
###6.1CRUCIAL ASSUMPTIONS
6.1.1 NORMALITY OF ERRORS: CHISQUARE GOODNESS OF FIT (LARGE SAMPLE TEST), ANDERSON DARLING,
QQ PLOT; ESSENTIAL FOR RELIABILITYF AND T TESTS; TRANSFORM SKEWED VARIABLES, SPECIFY MODEL BETTER,
INCREASE SAMPLE SIZE
6.1.2 HOMOSCEDASTICITY : 
BREUSCH PAGAN TEST, WHITE TEST,GOLDFIELD QUANDT TEST, GRAPHICAL METHOFS OF PLOTTING STDIZED ERRORS WITH VARIABLES
(SCATTER PLOT OF STANDARDIZED RESIDUALS WITH INDEPENDENT VARIABLES TO CHECK FUNNEL IN/OUT SHAPE,  
SAME WITH STANDARDIZDED PREDICTED VALUES  
OFTEN LEADS TO TRANSFORMATION OF DEPENDENT VARIABLE, CAN TIE IT BACK TO SKEWED DISTRIBUTION  
OF DEPENDENT);  
OLS DOES NOT GIVE BEST ESTIMATES,STD.ERROR WOULD BE HIGH, TREATMENT IS WEIGHTED OLS (USED IN GLMS) AS OLS GIVES  
EQUAL WEIGHT TO ALL OBSERVATIONS, ALSO GIVES BIASED STD. ERRORS OF B'S (DEFLATES) SO RELIABILITY OF
T TESTS IS IN QUESTION
6.1.3 MULTICOLINEARITY: 
PERFECT MC : NOT POSSIBLE TO ESTIMATE COEFFICIENTS 
HIGH BUT NOT PERFECT : VIF >1, CONFLICT IN F TEST AND T TEST; INFLATED STD. ERRORS, CAN REJECT SIGNIFICANT VARS.;
DROP VARIABLES, CONSOLIDATE, INCREASE SAMPLE SIZE
6.1.4 AUTOCORELATION: DURBIN WATSOM TEST, D = 2 THEN NO AC; ADD VARIABLES TO REMOVE AC, USE DUMMY VARS

### 6.2 VALIDATE HYPOTHESIS 
6.2.1WHY DO F TEST
6.2.2 T TEST - INDIVIDUAL B IS O WHILE OTHERS ARE NON ZERO OR ZERO, THAT IS WHY  
Under Null Hyp. B = 0 , i.e population parameter is o, so from multiple SRFs, the mean of Bs will  
be equal to population mean i.e 0. Std. error of this distribution of B, needs using standard deviation  
of B from the same, hence use t statistic.  
6.2.3 RESIDUAL TESTS
SPECIFICATION BIAS CAN BE PICKED UP, LIKE NON LINEAR RELATIONSHIPS
TEST FOR NORMALITY AND HOMSCEDASTICITY ALREADY DISCUSSED

### 6.3 TRANSFORMATIONS
NECESSARY FOR HETEROSCEDASTICITY, NORMLITY, NON LINEAR RELATIONSHIP
####6.3.1 GUIDELINES FOR TRANSFORMATION TO APPLY  
FOR HETEROSCEDASTICITY
FOR LINEARITY 

##7. VARIABLE SELECTION
###7.1 HOW TO SEE EFFECT OF ADDING/ REMOVING A VARIABLE
####7.1.1 USING CONCEPT OF PART AND PARTIAL CORRELATIONS
ADDING A VARIABLE IMPROVES R2 EQUAL TO SQ. OF SEMI-PARTIAL CORRELATION
####7.2 HOW TO TEST OF VARIABLE SHOULD BE ADDED
USE ADJUSTED R SQUARE
ESS/ TSS -> USE OF DF  -> ADJ RSQ =   1- (RSS/N-K-1)/(TSS/N-1)
%AGE DECRREASE IN RSS SHOULD BE MORE THAN % DECREASE IN DF BY ADDING VARIABLE TO DECREASE ADJ. R2
####7.3 PARTIAL F TEST FOR A BUNCH OF VARIABLES
WHAT IS THE Hypothesis
### NOTE : F TEST FOR VARIABLE SELECTION RELIES ON TESTING THE HYPOTHESIS THAT A DECREASE 
IN RSS IS ACCOMPISHED THAT IS NOT A MATTER OF CHANCE. 
BUT, IT DOES NOT ACCOUNT FOR AN INCREASE IN VARIANCE BY ADDING OF THE VARIABLE IF F TEST SUGGESTS SO,  
TEST FOR BIAS/VARIANCE IS ENTIRELY DIFFERENT DONE 

##8. ESTIMATE STANDARD ERROR OF REGRESSION I.E SD OF REGRESSION
MSE I.E  RSS/N-K-1 IS AN UNBIASED ESTIMATOR OF VARIANCE OF THE REGRESSION
##9. GOODNESS OF FIT MEASURES - LIMITATIONS OF RSQ FOR SELECTION
##10. HOW EQUATION IS USED FOR PREDICTION
### variance of yhat vs variance of E(Y|Xi)

SECTION B

# MODELING STRATEGY WITH REGRESSION
## DATA SELECTION
## DATA QUALITY
## DATA SAMPLING INTO TRAIN, TEST AND VAL or WHEN CAN WE USE CROSS VALIDATION - WHY?
## EDA - UNIVARIATE, BIVARIATE, CORRELATIONS, EXTREME VALUES CAPPING
AGAIN THIS PART IS MEANT TO ASSIST IN FORMULATING THE RELATIONSHIP
## FEATURE ENGINEERING BASED ON EDA, BUSINESS KNOWLEDGE, ITERATIONS
## VARIABLE SELECTION STRATEGY
### TRADITIONAL - FORWARD, BACKWARD AND MIXED SELECTION, SHORTCOMINGS
#### Uses Partial F test
### NEW - LASSO
## MODEL FITTING - UNDERSTANDING LOSS FUNCTIONS
## BIAS VS VARIANCE TRADE OFF -  MODELS PERFORMANCE ON A TEST SET USING AN ASSESSMENT CRITERIA
### MAKE MULTIPLE MODELS TO REDUCE SPEC. BIAS AS YOU LEARN AND BETTER HYPOTHESIS  
USE CV AND AN ASSESSMENT MEASURE LIKE MSE, AND DERIVE THE MEAN AND SD. OF THE MSE  
THEN CHOOSE THE SIMPLEST MODEL WITHIN 1 SD. OF THE MSE OF MODEL WITH LOWEST MSE  

### ASSESSMENT METRIC TO EVALUATE BEST MODEL
AIC, BIC, MSE, DEVIANCE

# OTHER STRATEGIES WITH REGRESSION FOR PRICING
## ADDING CONSTRAINTS OF MONOTONICITY OF COEFFICIENT FOR A FACTOR VARIABLES
As no. of faults increase, the coefficient should increase
## ADDING INTERACTIONS TO PROVIDE BENEFITS
AS NO. OF FAULTS INCREASE, BUT SO DO NUMBER OF CARS ON POLICY, SHOULD PROVIDE BENEFIT
So, add an interaction variable
## DELIBERATELY KEEPING SOME CATEGORICAL VARIABLES INSTEAD OF CONTINUOUS TO AVOID TOO THIN SEGMENTATION  
## FOR COMPETITIVE ADVANTAGE
Age of drivers could be continuous,and the premium on policy will change at end of policy period due  
to increase in age if it were continuous, may not if it were categorical, and birthday lies in the  
current policy period.   
You may want to do thin segmentatin on variables that have very high propensity for predicting risk
## TESTING FOR DISCRIMINATION USING INTERACTION
Can no. of females on policy be used for pricing, may be only along with no, of males?
## USING AN OFFSET TO FIX THE BASE PRICE USING A SEPARATE MODEL




```{r}
setwd("Documents/DS/SL201")
dir()
install.packages("xlsx")
library("xlsx")
library(ca)
boston <- read.csv("boston.xls")
data()

```

