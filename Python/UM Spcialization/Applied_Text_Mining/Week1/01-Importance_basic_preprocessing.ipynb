{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Mining - Importance\n",
    "Data is growing at rapid pace, about 20 exabytes per day, 80% of this is unstructured text data  \n",
    "\n",
    "#### Information is hidden in text data  \n",
    "Example of tweets, what information could one extract  \n",
    "1. Author  \n",
    "2. Location  \n",
    "3. Time  \n",
    "4. Topic or subject of tweet  \n",
    "5. Likes / Dislikes\n",
    "6. Shares\n",
    "7. Sentiment etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Use cases with text data.\n",
    "1. Parse text i.e read and split it in words  \n",
    "2. Identify and extract certain components from text  - Information retreival\n",
    "3. Tag/Classify documents \n",
    "4. Search for relevant documents  \n",
    "5. Sentiment analysis  \n",
    "6. Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primitive Constructs in text\n",
    "- Documents \n",
    "- Sentences \n",
    "    - First person / third person\n",
    "    - tense : past present future\n",
    "- Words / Tokens\n",
    "    - Subject\n",
    "    - Object\n",
    "    - Noun\n",
    "    - Adjective\n",
    "    - Prepositions\n",
    "    - Verb\n",
    "    - Adverb etc\n",
    "- Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Processing \n",
    "Text needs pre-processing, the steps *usually* (needs may differ) required are \n",
    "1. Reading the text, each line/sentence is read as a character string  \n",
    "2. Break sentences into words/tokens  \n",
    "3. Change case to lower\n",
    "4. Remove white spaces from front, end  \n",
    "5. Remove common occuring words like prepositions, often called 'stop' word removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = 'Ethics are built right into the ideals and objectives of the united nations'\n",
    "len(text)\n",
    "tokens = text.split(' ')\n",
    "#type(tokens) -  list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of \n",
    "1. sentence split into token  \n",
    "2. case identification  \n",
    "3. finding substrings\n",
    "4. finding unique tokens\n",
    "\n",
    "**Use of list comprehensions to achieve this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'ideals',\n",
       " 'objectives',\n",
       " 'united',\n",
       " 'nations']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that are more than 3 chrs long\n",
    "wrds1 = [x for x in tokens if len(x) >3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that start with a capital letter\n",
    "wrds2 = [x for x in tokens if x.istitle()]\n",
    "wrds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'ideals', 'objectives', 'nations']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that end with 's'\n",
    "wrds3 = [x for x in tokens if x.endswith('s')]\n",
    "wrds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"To be or not to be\"\n",
    "tokens2 = text2.split(' ')\n",
    "\n",
    "# Change case to lower\n",
    "wrds4 = [x.lower() for x in tokens2 ]\n",
    "\n",
    "# Unique words from a list using set()\n",
    "set(wrds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Examining methods available on string stype\n",
    "s.startswith() - examine if string starts with a character  \n",
    "s.endswith() - ends with a character  \n",
    "t in s -  if a substring is part of the string   \n",
    "s.isupper()   \n",
    "s.islower()  \n",
    "s.istitle() - title case, i.e first letter is capital  \n",
    "s.isalpha() - only has alphabets\n",
    "s.isdigit() -  only comprised of digits\n",
    "s.isalnum() -  has both, i.e alphanumeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for String operation\n",
    "s.lower(), s.upper() - convert to upper or lower  \n",
    "s.split() & s.join() -  split based on a character string given as argument  \n",
    "s.splitlines()  \n",
    "s.strip()  - strips whitespaces from front and back  \n",
    "s.rstrip()  - only from back\n",
    "s.find()  - finds first occurence of the pattern from start  \n",
    "s.rfind()  - just given the index couting backwards  \n",
    "s.replace(u,v)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'agod', 'g', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ouagodougou'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split & Join functions are opposite of each other\n",
    "text3 = \"ouagodougou\"\n",
    "tokens = text3.split(\"ou\")\n",
    "print(tokens)\n",
    "\n",
    "word4 = \"ou\"\n",
    "word4.join(tokens)\n",
    "# join when given an arguments as a list, places the word between pairs in the list, an action opposite to splitting\n",
    "# using the string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'a', 'm', ' ', 'l', 'e', 'a', 'r', 'n', 'i', 'n', 'g', ' ', 'N', 'L', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Breaking a string into characters\n",
    "text4 = \"I am learning NLP\" \n",
    "# Method 1 : string comprehension\n",
    "chrs = [j for j in text4]\n",
    "chrs\n",
    "\n",
    "# Method 2 : coercion to a list\n",
    "print(list(text4))\n",
    "\n",
    "# What will not work\n",
    "#text4.split(\"\") # split needs a charcter to split on, arleast a whitespace \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', 'A', 'quick', 'brown', 'fox', 'jumped', 'over', 'a', 'lazy', 'dog']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A quick brown fox jumped over a lazy dog'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Operations\n",
    "#1. Whitespace removal, use method 'strip' on string , NOT on list available from split method\n",
    "text5 =  \"   A quick brown fox jumped over a lazy dog\"\n",
    "tokens = text5.split(\" \")\n",
    "print(tokens)\n",
    "text5_clean = text5.strip()\n",
    "text5_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 38]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A quick brOwn fOx jumped Over a lazy dOg'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Find and replace  \n",
    "# 'find' method returns the index of the first occurence of string patters from the start,\n",
    "# rstring gives the same index from reverse\n",
    "print ([text5_clean.find(\"o\") , text5_clean.rfind(\"o\")])\n",
    "#len(text5_clean)\n",
    "\n",
    "# replace finds a pattern and replaces in the entire string\n",
    "text5_clean.replace(\"o\", \"O\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
